{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector as ccnx\n",
    "import csv\n",
    "import re\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#python connector setup\n",
    "mydb = ccnx.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"root\",\n",
    "    database=\"edfs\"\n",
    ")\n",
    "mycursor = mydb.cursor(buffered=True)\n",
    "\n",
    "####################\n",
    "# Helper Functions #\n",
    "####################\n",
    "\n",
    "def Sort_Tuple(tup: list, idx: int) -> list:\n",
    "    '''\n",
    "    Return the sorted list of tuples by the element of the tuple\n",
    "    Args:\n",
    "        tup (list): unsorted list of tuples\n",
    "        idx (int): the element of the tuple to sort by\n",
    "    Returns:\n",
    "        (list) Sorted list of tuples\n",
    "    '''\n",
    "    return(sorted(tup, key = lambda x: x[idx]))\n",
    "\n",
    "def key_idx(str_list):\n",
    "    '''\n",
    "    Return the index of 'Country Name' if it exists in the dataset, and 0 if\n",
    "    the column name is not present\n",
    "    Args:\n",
    "        str_list (list): the list of column names\n",
    "    Returns:\n",
    "        (int) the index returned\n",
    "    '''\n",
    "    try:\n",
    "        return str_list.index('Country Name')\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def key_cleaning(row):\n",
    "    #key cleaning\n",
    "    clean_key =  re.sub(r'[^A-Za-z0-9 ]+', '', row[0]).replace(\" \", \"_\")\n",
    "    key = clean_key if clean_key != \"\" else \"invalid_key\"\n",
    "    if key.isnumeric() and key.length() > 0:\n",
    "        key = f\"t{key}\"\n",
    "    if len(key) >= 64:\n",
    "        key = key[0:40]\n",
    "    return key\n",
    "\n",
    "####################\n",
    "# API Functions    #\n",
    "####################\n",
    "\n",
    "def read_dataset(path):\n",
    "    # (partition_name, csv_index, comma-separated-string)\n",
    "    list_of_tuples = getPartitionData(path)\n",
    "    list_of_lists = [tuple[2].split(\",\") for tuple in list_of_tuples]\n",
    "    df = pd.DataFrame(list_of_lists)\n",
    "\n",
    "    new_header = df.iloc[0] #grab the first row for the header\n",
    "    df = df[1:] #take the data less the header row\n",
    "    df.columns = new_header #set the header row as the df header\n",
    "\n",
    "    df = df.drop([\"Country Code\", \"Series Code\"], \"columns\")\n",
    "\n",
    "    df_melted = df.melt(id_vars=[\"Country Name\", \"Series Name\"],\n",
    "        var_name=\"Year\",\n",
    "        value_name=\"Value\")\n",
    "\n",
    "    df_melted[\"Year\"] = df_melted[\"Year\"].str[0:4]\n",
    "\n",
    "    df_melted = df_melted.loc[df_melted.Value.str.isnumeric()].copy()\n",
    "\n",
    "    # change columns names\n",
    "    new_columns = list()\n",
    "    columns = df_melted.columns\n",
    "    for c in columns:\n",
    "            new_columns.append(c.replace(\" \",\"_\"))\n",
    "\n",
    "    # change column names in dataframe\n",
    "    df_melted.columns = new_columns\n",
    "\n",
    "    return df_melted.astype({'Year':'int', 'Value': 'float'})\n",
    "\n",
    "def seek(path):\n",
    "    '''\n",
    "    Returns the filestructure that matches the specified path\n",
    "    Args:\n",
    "        str_list (list): the list of column names\n",
    "    Returns:\n",
    "        (int) the index returned\n",
    "    '''\n",
    "    seek_statement = \"SELECT * FROM df WHERE path = %s\"\n",
    "    mycursor.execute(seek_statement, (path,))\n",
    "    myresult = mycursor.fetchall()\n",
    "    return myresult\n",
    "\n",
    "def mkdir(path, name):\n",
    "    '''\n",
    "    Create the directory at the specfied path in the filesystem\n",
    "    Args:\n",
    "        path (str): the path to the directory's home\n",
    "        name (str): the name of the directory\n",
    "    Returns:\n",
    "        output (str): success or failure of the operation\n",
    "    '''\n",
    "    result = seek(path)\n",
    "    if result:\n",
    "        if result[0][1] == \"DIRECTORY\":\n",
    "            pathname = f\"{path}/{name}\"\n",
    "            dup_result = seek(pathname)\n",
    "            if not dup_result:\n",
    "                insert_statement = \"INSERT INTO df VALUES (%s, 'DIRECTORY')\"\n",
    "                mycursor.execute(insert_statement, (pathname,))\n",
    "                mydb.commit()\n",
    "                output = f\"directory {name} created\"\n",
    "            else:\n",
    "                output = \"directory already exists\"\n",
    "    else:\n",
    "        output = f\"Invalid path: {path}\"\n",
    "    return output\n",
    "\n",
    "def rm(path, name):\n",
    "    '''\n",
    "    Removes the directory at the specfied path in the filesystem\n",
    "    Args:\n",
    "        path (str): the path to the directory's home\n",
    "        name (str): the name of the directory\n",
    "    Returns:\n",
    "        output (str): success or failure of the operation\n",
    "    '''\n",
    "    result = seek(path)\n",
    "    filepath =  f\"{path}/{name}\"\n",
    "    if result:\n",
    "        select_statement = \"SELECT * FROM df WHERE path LIKE %s\"\n",
    "        mycursor.execute(select_statement, (filepath + \"%\",))\n",
    "        result = mycursor.fetchall()\n",
    "        if len(result) != 1:\n",
    "            output = \"invalid deletion\"\n",
    "        else:\n",
    "            delete_statement = \"DELETE FROM df WHERE path LIKE %s\"\n",
    "            mycursor.execute(delete_statement, (filepath,)) #TODO: adding % here will add -r functionality\n",
    "            mydb.commit()\n",
    "            output = f\"{filepath} deleted\"\n",
    "    else:\n",
    "        output = f\"Invalid path: {filepath}\"\n",
    "    return output\n",
    "\n",
    "def ls(path):\n",
    "    '''\n",
    "    Returns the contents of the directory at the specfied path in the filesystem\n",
    "    Args:\n",
    "        path (str): the path to the directory's home\n",
    "        name (str): the name of the directory\n",
    "    Returns:\n",
    "        output (str): success or failure of the operation\n",
    "    '''\n",
    "    result = seek(path)\n",
    "    if result:\n",
    "        if result[0][1] == \"FILE\":\n",
    "            output = \"Cannot run 'ls' on files\"\n",
    "        elif result[0][1] == \"DIRECTORY\":\n",
    "            ls_statement = \"SELECT * FROM df WHERE path REGEXP %s\"\n",
    "            mycursor.execute(ls_statement, (f\"^{path}\\/[^\\/]+$\",))\n",
    "            output = mycursor.fetchall()\n",
    "    else:\n",
    "        output = f\"Invalid path: {path}\"\n",
    "    return output\n",
    "\n",
    "def getPartitionLocations(path):\n",
    "    '''\n",
    "    Returns the blockLocations that match the file at the specified\n",
    "    Args:\n",
    "        path (str): the path to the file\n",
    "    Returns:\n",
    "        output (obj): the blockLocations in a list of tuples\n",
    "    '''\n",
    "    cat_statement = \"SELECT * FROM blockLocations WHERE path = %s\"\n",
    "    mycursor.execute(cat_statement, (path,))\n",
    "    result = mycursor.fetchall()\n",
    "    return result\n",
    "\n",
    "def readPartition(path, partition_name):\n",
    "    '''\n",
    "    Returns the contents of a specified partition_name\n",
    "    Args:\n",
    "        path (str): the path to the file\n",
    "        partition_name: the name of the partition\n",
    "    Returns:\n",
    "        [list of (tuple)]: the data contents of the partition\n",
    "    '''\n",
    "    mycursor.execute(f\"SELECT * FROM {partition_name} WHERE path = %s\", (path,))\n",
    "    result = mycursor.fetchall()\n",
    "    partition_data = []\n",
    "    for line in result:\n",
    "        partition_data.append((partition_name, line[1], line[2]))\n",
    "    return partition_data\n",
    "\n",
    "def cat(path):\n",
    "    '''\n",
    "    Returns the contents the file at the specified path\n",
    "    Args:\n",
    "        path (str): the path to the file\n",
    "    Returns:\n",
    "        output (obj): the text of the file\n",
    "    '''\n",
    "    output = \"\"\n",
    "    sorted_data_list = getPartitionData(path)\n",
    "    for s in sorted_data_list:\n",
    "        output += s[2] +\"\\n\"\n",
    "    return output\n",
    "\n",
    "def getPartitionData(path):\n",
    "    '''\n",
    "    Returns the contents the file at the specified path\n",
    "    Args:\n",
    "        path (str): the path to the file\n",
    "    Returns:\n",
    "        output (obj): the text of the file\n",
    "    '''\n",
    "    result = seek(path)\n",
    "    output = \"\"\n",
    "    if result:\n",
    "        if result[0][1] == \"DIRECTORY\":\n",
    "            output = \"Cannot run 'cat' on directories\"\n",
    "        elif result[0][1] == \"FILE\":\n",
    "            myresult = getPartitionLocations(path)\n",
    "            data_list = []\n",
    "            for partition in myresult:\n",
    "                data_list = data_list + readPartition(path, partition[1])\n",
    "            sorted_data_list = Sort_Tuple(data_list, 1)\n",
    "            return sorted_data_list\n",
    "    else:\n",
    "        output = f\"Invalid path: {path}\"\n",
    "    return output\n",
    "\n",
    "def put(path, name, csv):\n",
    "    '''\n",
    "    places the file from a local directory into the EDFS\n",
    "    Args:\n",
    "        path (str): the path to the file\n",
    "        name (str): the name of the file to be created\n",
    "        csv (str): the path to the csv file to be placed\n",
    "    Returns:\n",
    "        output (str): the success or failure of the operation\n",
    "    '''\n",
    "    result = seek(path)\n",
    "    if result:\n",
    "        if result[0][1] == \"DIRECTORY\":\n",
    "            dup_result = seek(f\"{path}/{name}\")\n",
    "            if not dup_result:\n",
    "                hash_lists = hash(path, name, csv)\n",
    "                output = f\"file {name} created\"\n",
    "            else:\n",
    "                output = \"file already exists\"\n",
    "        else:\n",
    "            output = \"cannot place a file in a file\"\n",
    "    else:\n",
    "        output = f\"Invalid path: {path}\"\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "def hash(path, name, csv_file):\n",
    "    '''\n",
    "    Alters the metadata to allocate new datanotes if needed and places the file\n",
    "    data into the nodes\n",
    "    Args:\n",
    "        path (str): the path to the file\n",
    "        name (str): the name of the file to be created\n",
    "        csv (str): the path to the csv file to be placed\n",
    "    Returns:\n",
    "        key_list (list): the list of keys to datanodes that have been\n",
    "        allocated to\n",
    "    '''\n",
    "\n",
    "    #execute metadata alter\n",
    "    meta_statement = \"INSERT INTO df VALUES (%s, 'FILE');\"\n",
    "    mycursor.execute(meta_statement, (f\"{path}/{name}\",))\n",
    "    mydb.commit()\n",
    "    with open(csv_file) as f:\n",
    "\n",
    "        key_list, csv_counter = {}, 0\n",
    "        reader = csv.reader(f, delimiter=',')\n",
    "        header = next(reader)\n",
    "        key_index = key_idx(header)\n",
    "        key = key_cleaning(header)\n",
    "\n",
    "        #TODO: modularize this create code JFC\n",
    "        try:\n",
    "            create_statement = f\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS {key}(\n",
    "                    path varchar(255),\n",
    "                    data_index int,\n",
    "                    data text,\n",
    "                    FOREIGN KEY(path) REFERENCES df(path) ON DELETE CASCADE\n",
    "                )\"\"\"\n",
    "            insert_hash_statement = f\"INSERT INTO {key} VALUES (%s, %s, %s);\"\n",
    "            mycursor.execute(create_statement)\n",
    "            mydb.commit()\n",
    "            mycursor.execute(insert_hash_statement, (path + \"/\" + name, csv_counter, ','.join(header)))\n",
    "            mydb.commit()\n",
    "            key_list[key] = None\n",
    "            csv_counter += 1\n",
    "        except:\n",
    "            output = f\"ERROR: {mycursor.statement}\"\n",
    "\n",
    "        for row in reader:\n",
    "            key = key_cleaning(row)\n",
    "            #try insert data into datanode\n",
    "            try:\n",
    "                create_statement = f\"\"\"\n",
    "                    CREATE TABLE IF NOT EXISTS {key}(\n",
    "                        path varchar(255),\n",
    "                        data_index int,\n",
    "                        data text,\n",
    "                        FOREIGN KEY(path) REFERENCES df(path) ON DELETE CASCADE\n",
    "                    )\"\"\"\n",
    "                insert_hash_statement = f\"INSERT INTO {key} VALUES (%s, %s, %s);\"\n",
    "                mycursor.execute(create_statement)\n",
    "                mydb.commit()\n",
    "                mycursor.execute(insert_hash_statement, (path + \"/\" + name, csv_counter, ','.join(row)))\n",
    "                mydb.commit()\n",
    "                key_list[key] = None\n",
    "                csv_counter += 1\n",
    "            except:\n",
    "                output = f\"ERROR: {mycursor.statement}\"\n",
    "                rm(path, name)\n",
    "                # return output\n",
    "\n",
    "        #write data into datanodes\n",
    "        for key in key_list.keys():\n",
    "             block_statement = \"INSERT INTO blockLocations VALUES(%s, %s);\"\n",
    "             mycursor.execute(block_statement, (f\"{path}/{name}\", key))\n",
    "        mydb.commit()\n",
    "        return key_list\n",
    "\n",
    "######################\n",
    "# Database Functions #\n",
    "######################\n",
    "\n",
    "def delete(list):\n",
    "    '''\n",
    "    Drops all tables in the list from the edfs\n",
    "    Args:\n",
    "        list (list): the list of table names to drop\n",
    "    Returns:\n",
    "        (str): the success or failure of the operation\n",
    "    '''\n",
    "    try:\n",
    "        for item in list:\n",
    "            drop_table = f\"DROP TABLE {key}\"\n",
    "            mycursor.execute(drop_table)\n",
    "            mydb.commit()\n",
    "        return \"Dropped tables\"\n",
    "    except:\n",
    "        return \"Database drop error\"\n",
    "\n",
    "def new_env(edfs):\n",
    "    '''\n",
    "    Executes EDFS SQL setup queries\n",
    "    Args:\n",
    "        edfs (str): the name of the EDFS filesystel to setup\n",
    "    Returns:\n",
    "        (str): the success or failure of the operation\n",
    "    '''\n",
    "    env_statements = [\n",
    "            f\"CREATE DATABASE {edfs}\",\n",
    "            f\"USE {edfs}\",\n",
    "            \"\"\"\n",
    "                CREATE TABLE df (\n",
    "                    path varchar(255),\n",
    "                    type varchar(255),\n",
    "                    PRIMARY KEY(path)\n",
    "                )\"\"\",\n",
    "            \"INSERT INTO df VALUES ('/root', 'DIRECTORY')\",\n",
    "            \"\"\"\n",
    "                CREATE TABLE blockLocations (\n",
    "                    path varchar(255),\n",
    "                    partition_name varchar(255),\n",
    "                    CONSTRAINT FOREIGN KEY (path) REFERENCES df(path) ON DELETE CASCADE\n",
    "                )\"\"\"\n",
    "    ]\n",
    "    try:\n",
    "        for s in env_statements:\n",
    "            mycursor.execute(s)\n",
    "        mydb.commit()\n",
    "        return f\"{edfs} created\"\n",
    "    except:\n",
    "        return \"Database error\"\n",
    "\n",
    "def delete_env(edfs):\n",
    "    '''\n",
    "    Drops the EDFS database entirely\n",
    "    Args:\n",
    "        edfs (str): the name of the EDFS filesystel to drop\n",
    "    Returns:\n",
    "        (str): the success or failure of the operation\n",
    "    '''\n",
    "    try:\n",
    "        drop_database = f\"DROP DATABASE {edfs};\"\n",
    "        mycursor.execute(drop_database)\n",
    "        mydb.commit()\n",
    "    except:\n",
    "        return \"Database error\"\n",
    "    return  f\"{edfs} deleted\"\n",
    "\n",
    "def start_env(edfs):\n",
    "    '''\n",
    "    Uses EDFS database\n",
    "    Args:\n",
    "        edfs (str): the name of the EDFS filesystem to run\n",
    "    Returns:\n",
    "        (str): the success or failure of the operation\n",
    "    '''\n",
    "    try:\n",
    "        use_database = f\"USE {edfs}\"\n",
    "        mycursor.execute(use_database)\n",
    "    except:\n",
    "        return \"Database error\"\n",
    "    return  f\"{edfs} started\"\n",
    "\n",
    "# def test_edfs(argv):\n",
    "\n",
    "#     edfs = \"edfs\"\n",
    "\n",
    "#     #Testing\n",
    "#     if \"--delete\" in argv:\n",
    "#         print(delete_env(edfs))\n",
    "#     elif \"--new\" in argv:\n",
    "#         print(new_env(edfs))\n",
    "#     elif \"--restart\" in argv:\n",
    "#         print(delete_env(edfs))\n",
    "#         print(new_env(edfs))\n",
    "#     else:\n",
    "#         print(start_env(edfs))\n",
    "#         print(mkdir(\"/root\", \"foo\"))\n",
    "#         print(mkdir(\"/root/foo\", \"bar\"))\n",
    "#         #todo: put check to make sure that the file source exists\n",
    "#         print(put(\"/root/foo\", \"data\", \"../datasets/sql-edfs/data.csv\"))\n",
    "#         print(cat(\"/root/foo/data\"))\n",
    "#         print(ls(\"/root/foo\"))\n",
    "#         print(rm(\"/root\", \"data\"))\n",
    "#         print(ls(\"/tree\"))\n",
    "\n",
    "\n",
    "#     # test_edfs(sys.argv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'edfs deleted'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edfs=\"edfs\"\n",
    "delete_env(edfs)\n",
    "# new_env(edfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'edfs created'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_env(edfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'edfs started'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_env(edfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('/root/user', 'DIRECTORY')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls(\"/root\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put(mycursor, \"/root/foo\", \"data\", \"datasets/sql-edfs/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datasets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/danieldacosta/Documents/USC/dsci551/distributed-file-system/main.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/danieldacosta/Documents/USC/dsci551/distributed-file-system/main.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m datasets\u001b[39m/\u001b[39msql\u001b[39m-\u001b[39medfs\u001b[39m/\u001b[39mCookingData\u001b[39m.\u001b[39mcsv\n",
      "\u001b[0;31mNameError\u001b[0m: name 'datasets' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"datasets/sql-edfs/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.sample(50, random_state=42).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country Name</th>\n",
       "      <th>Country Code</th>\n",
       "      <th>Series Name</th>\n",
       "      <th>Series Code</th>\n",
       "      <th>1960 [YR1960]</th>\n",
       "      <th>1961 [YR1961]</th>\n",
       "      <th>1962 [YR1962]</th>\n",
       "      <th>1963 [YR1963]</th>\n",
       "      <th>1964 [YR1964]</th>\n",
       "      <th>1965 [YR1965]</th>\n",
       "      <th>...</th>\n",
       "      <th>2012 [YR2012]</th>\n",
       "      <th>2013 [YR2013]</th>\n",
       "      <th>2014 [YR2014]</th>\n",
       "      <th>2015 [YR2015]</th>\n",
       "      <th>2016 [YR2016]</th>\n",
       "      <th>2017 [YR2017]</th>\n",
       "      <th>2018 [YR2018]</th>\n",
       "      <th>2019 [YR2019]</th>\n",
       "      <th>2020 [YR2020]</th>\n",
       "      <th>2021 [YR2021]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>Central Europe and the Baltics</td>\n",
       "      <td>CEB</td>\n",
       "      <td>Access to electricity (% of population)</td>\n",
       "      <td>EG.ELC.ACCS.ZS</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>99.8278344126722</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>99.9796400333302</td>\n",
       "      <td>..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Antigua and Barbuda</td>\n",
       "      <td>ATG</td>\n",
       "      <td>Access to electricity (% of population)</td>\n",
       "      <td>EG.ELC.ACCS.ZS</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Haiti</td>\n",
       "      <td>HTI</td>\n",
       "      <td>Access to electricity (% of population)</td>\n",
       "      <td>EG.ELC.ACCS.ZS</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>...</td>\n",
       "      <td>37.9000015258789</td>\n",
       "      <td>38.6978759765625</td>\n",
       "      <td>39.496410369873</td>\n",
       "      <td>40.8362846374512</td>\n",
       "      <td>40.4000015258789</td>\n",
       "      <td>43.7492713928223</td>\n",
       "      <td>44.962345123291</td>\n",
       "      <td>45.990234375</td>\n",
       "      <td>46.9255332946777</td>\n",
       "      <td>..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>Africa Eastern and Southern</td>\n",
       "      <td>AFE</td>\n",
       "      <td>Access to electricity (% of population)</td>\n",
       "      <td>EG.ELC.ACCS.ZS</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>...</td>\n",
       "      <td>31.8443844038242</td>\n",
       "      <td>31.794159992766</td>\n",
       "      <td>32.001026781227</td>\n",
       "      <td>33.8719104646129</td>\n",
       "      <td>38.8801732244203</td>\n",
       "      <td>40.261357595893</td>\n",
       "      <td>43.061876950924</td>\n",
       "      <td>44.2708604789338</td>\n",
       "      <td>45.8034852293869</td>\n",
       "      <td>..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Mexico</td>\n",
       "      <td>MEX</td>\n",
       "      <td>Access to electricity (% of population)</td>\n",
       "      <td>EG.ELC.ACCS.ZS</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>...</td>\n",
       "      <td>99.1116333007813</td>\n",
       "      <td>99.1476974487305</td>\n",
       "      <td>99.1729278564453</td>\n",
       "      <td>99</td>\n",
       "      <td>99.5</td>\n",
       "      <td>100</td>\n",
       "      <td>99.5</td>\n",
       "      <td>99.5999984741211</td>\n",
       "      <td>99.4000015258789</td>\n",
       "      <td>..</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Country Name Country Code  \\\n",
       "208  Central Europe and the Baltics          CEB   \n",
       "6               Antigua and Barbuda          ATG   \n",
       "79                            Haiti          HTI   \n",
       "204     Africa Eastern and Southern          AFE   \n",
       "117                          Mexico          MEX   \n",
       "\n",
       "                                 Series Name     Series Code 1960 [YR1960]  \\\n",
       "208  Access to electricity (% of population)  EG.ELC.ACCS.ZS            ..   \n",
       "6    Access to electricity (% of population)  EG.ELC.ACCS.ZS            ..   \n",
       "79   Access to electricity (% of population)  EG.ELC.ACCS.ZS            ..   \n",
       "204  Access to electricity (% of population)  EG.ELC.ACCS.ZS            ..   \n",
       "117  Access to electricity (% of population)  EG.ELC.ACCS.ZS            ..   \n",
       "\n",
       "    1961 [YR1961] 1962 [YR1962] 1963 [YR1963] 1964 [YR1964] 1965 [YR1965]  \\\n",
       "208            ..            ..            ..            ..            ..   \n",
       "6              ..            ..            ..            ..            ..   \n",
       "79             ..            ..            ..            ..            ..   \n",
       "204            ..            ..            ..            ..            ..   \n",
       "117            ..            ..            ..            ..            ..   \n",
       "\n",
       "     ...     2012 [YR2012]     2013 [YR2013]     2014 [YR2014]  \\\n",
       "208  ...               100               100               100   \n",
       "6    ...               100               100               100   \n",
       "79   ...  37.9000015258789  38.6978759765625   39.496410369873   \n",
       "204  ...  31.8443844038242   31.794159992766   32.001026781227   \n",
       "117  ...  99.1116333007813  99.1476974487305  99.1729278564453   \n",
       "\n",
       "        2015 [YR2015]     2016 [YR2016]     2017 [YR2017]    2018 [YR2018]  \\\n",
       "208               100  99.8278344126722               100              100   \n",
       "6                 100               100               100              100   \n",
       "79   40.8362846374512  40.4000015258789  43.7492713928223  44.962345123291   \n",
       "204  33.8719104646129  38.8801732244203   40.261357595893  43.061876950924   \n",
       "117                99              99.5               100             99.5   \n",
       "\n",
       "        2019 [YR2019]     2020 [YR2020] 2021 [YR2021]  \n",
       "208               100  99.9796400333302            ..  \n",
       "6                 100               100            ..  \n",
       "79       45.990234375  46.9255332946777            ..  \n",
       "204  44.2708604789338  45.8034852293869            ..  \n",
       "117  99.5999984741211  99.4000015258789            ..  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('datasets/Access_Electricity.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"datasets/sql-edfs/CookingData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df.sample(50, random_state=42).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_csv('datasets/Access_Fuels.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"datasets/Human_Capital_Index.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df.sample(50, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.to_csv(\"datasets/Human_Capital_Index_Sample.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ed29fcc266c631214eb0a32dcb461d51a7279cf73c87ecfbb65b364d13f4dbad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
