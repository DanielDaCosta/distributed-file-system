{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1cd8b98",
   "metadata": {},
   "source": [
    "## DSCI 551 Project\n",
    "\n",
    "Create an emulation-based system for distributed file storage and parallel computation. <br>\n",
    "1. Building an emulated distributed file system (EDFS) <br>\n",
    "- EDFS should support the following commands, similar to that in HDFS:\n",
    "    - mkdir: create a directory in file system, e.g., *mdkir /user/john\n",
    "    - ls: listing content of a given directory, e.g., *ls /user\n",
    "    - cat: display content of a file, e.g., *cat /user/john/hello.txt\n",
    "    - rm: remove a file from the file system, e.g., *rm /user/john/hello.txt\n",
    "    - put: uploading file to a file system, e.g., *put (car.csv, /user/john, k = # partitions)* will upload a file cars.csv to the directory /user/john in EDFS. **But note that the file should be stored in k partitions, and the file system should remember where the partitions are stored.** you should design a method to partition data. you may also have the user indicate the method, e.g., hashing on certain car attribute, in the put method. \n",
    "    - getPartitionLocations(file): this method will return the location of partitions of the file.\n",
    "    - readPartition(file, partition #): this method will return the content of partion # of the specified file. the portioned data will be needed in the second task for parallel processing. \n",
    "- **Note that EDFS should store the metadata about the file system** (similar to that in NameNode of HDFS, but much simplified). **Metadata include file system structure, attributes of files, and location of partitions storing the contents of files.** You can limit the type of files stored in the file system to certain format, e.g., .csv or JSON. \n",
    "<br><br>\n",
    "\n",
    "#### Google Firebase address : https://dsci551-project-52d43-default-rtdb.firebaseio.com/\n",
    "### Statistical Capacity Indicators \n",
    "###### Statistical Capacity Indicators provides information on various aspects of national statistical systems of developing countries, including an overall country-level statistical capacity indicator. Last Updated:02/03/2021\n",
    "#### Data from : https://databank.worldbank.org/source/statistical-capacity-indicators# \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6acf8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import requests\n",
    "import csv\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "\n",
    "firebase_url = 'https://dsci551-project-52d43-default-rtdb.firebaseio.com/'\n",
    "\n",
    "def seek(path):\n",
    "    if not re.search('.json', path):\n",
    "        url = firebase_url + path + '.json'\n",
    "        \n",
    "    try:\n",
    "        rget = requests.get(url)\n",
    "        return rget\n",
    "    except:\n",
    "        print('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6975237",
   "metadata": {},
   "source": [
    "### MKDIR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b6870a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir(path):\n",
    "    if seek(path).json() is None:\n",
    "        url = firebase_url + path + '.json'\n",
    "#         print (url)\n",
    "        r = requests.put(url,data)\n",
    "        print (r.url)\n",
    "    else:\n",
    "        print ('Directory ', path, ' already exists')\n",
    "\n",
    "# requests.put('https://dsci551-project-52d43-default-rtdb.firebaseio.com/mk.json', '{\"test\":1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb599fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir('NameNode/root/user') #Change to user input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c295f0",
   "metadata": {},
   "source": [
    "### LS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056892c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ls(path):\n",
    "    # ADDING \"NameNode/root/\" to Firebase request path\n",
    "    if not re.search('NameNode/root', path):\n",
    "        path = 'NameNode/root/' + path\n",
    "    \n",
    "    if seek(path).json() is not None:\n",
    "        for key in seek(path).json().keys():\n",
    "            print(key)\n",
    "    else:\n",
    "        print (\" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d359e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls('data2/China') # Change to user input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c21fc7a",
   "metadata": {},
   "source": [
    "### RM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873d1e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm(path):\n",
    "    path = path.replace('.csv','')\n",
    "    if seek(path).json() is None:\n",
    "        print ('Directory not found')\n",
    "    else:\n",
    "        url = firebase_url + path + '.json'\n",
    "        d = requests.delete(url)\n",
    "        if d.status_code == 200:\n",
    "            print(path, 'was succefully deleted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfe14e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm('NameNode/root/user')\n",
    "rm('DataNode')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93686eea",
   "metadata": {},
   "source": [
    "### PUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ce7a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleans column names for firebase json object key\n",
    "def varname (var):\n",
    "    key = re.sub(r'[^A-Za-z0-9 ]+', '', var).replace(\" \", \"_\")\n",
    "    names = key if key != \"\" else \"invalid_key\"\n",
    "    return names\n",
    "\n",
    "def mtime():\n",
    "#     to revert back\n",
    "    #datetime.datetime.utcfromtimestamp(int(mtime)/1000).strftime('%Y-%-m-%-d %I:%M:%S') \n",
    "    return (datetime.datetime.now().timestamp()*1000)\n",
    "\n",
    "def filesize(file): #file size in bytes\n",
    "    return  os.path.getsize(file)\n",
    "\n",
    "def indexing(dicts):\n",
    "    dt = dict()\n",
    "    for k,v in dicts.items():\n",
    "        i = int(k.replace('p',''))\n",
    "        dt[i] = v\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f3e8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def record_partition(path, country, filename, url):\n",
    "    try:\n",
    "        npath = firebase_url + path + \"/\" + filename + \"/partitions.json\"\n",
    "    #     print (npath ,\":\", url)\n",
    "        mdata = {country : url}\n",
    "        putMeta = requests.patch(npath, json.dumps(mdata))\n",
    "        if putMeta.status_code == 400: print(country)\n",
    "    #     print (putMeta)\n",
    "    except:\n",
    "        print (country)\n",
    "\n",
    "def file_mdata(path, file, filename):\n",
    "    npath = firebase_url + path + \"/\" + filename + \".json\"\n",
    "    mdata = {'ctime': mtime(),\n",
    "             'name': file,\n",
    "             'type': 'FILE',\n",
    "             'filesize':filesize(file)}\n",
    "    putMeta = requests.patch(npath, json.dumps(mdata))\n",
    "    \n",
    "\n",
    "# partition by Country (Original plan)\n",
    "def put(file, path):\n",
    "    filename = file.replace(\".csv\",\"\")\n",
    " \n",
    "    # creating dictinary to organize data into correct json format. \n",
    "    # added 'file name' to the dictionary to help differentiate data from different files\n",
    "    dc = dict()\n",
    "    with open(file, encoding = 'utf-8') as csvfile:\n",
    "        csvReader = csv.reader(csvfile)\n",
    "        \n",
    "        for index, row in enumerate(csvReader):\n",
    "            cname = varname(row[0])\n",
    "            n = 'p' + str(index)\n",
    "            if cname in dc:\n",
    "                dc[cname][n] = (';'.join(row))\n",
    "            else:\n",
    "                dc[cname]={n:(';'.join(row))}\n",
    "    \n",
    "    if seek(path + '/' +filename).json() is None:\n",
    "        for key, val in dc.items():\n",
    "            url = firebase_url + 'DataNode/' + key + '/' + filename + '.json'\n",
    "            putResponse = requests.put(url, json.dumps(val))\n",
    "            if putResponse.status_code == 200:\n",
    "                record_partition (path, key, filename, putResponse.url)\n",
    "            else:\n",
    "                print (file, 'failed to uploaded at partition', key)\n",
    "        \n",
    "        print (file, 'was succesfully uploaded to', path)\n",
    "        \n",
    "        file_mdata(path, file, filename)\n",
    "        #add metadata information.\n",
    "    else:\n",
    "        print (file, \"already exists in\", path)\n",
    "            \n",
    "        \n",
    "    return dc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65f2810",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# filename = 'Stats_Cap_Ind.csv'\n",
    "filename = 'Human_Capital_Index.csv'\n",
    "path = 'NameNode/root/user'\n",
    "dc = put(filename, path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92c971d",
   "metadata": {},
   "source": [
    "### getPartition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf1b498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPartitionLocation(file):\n",
    "    file = file.replace(\".csv\",\"\")\n",
    "    path = \"NameNode/root/\" + file + \"/partitions\"\n",
    "    rpath = seek(path)\n",
    "    partition = requests.get(rpath.url)\n",
    "    pdict = partition.json()       \n",
    "    \n",
    "    return pdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e671687f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"user/Stats_Cap_Ind\"\n",
    "getPartitionLocation(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b28ba4",
   "metadata": {},
   "source": [
    "### readPartition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9631025c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readPartition(file, partition):\n",
    "    pdict = getPartitionLocation(file)\n",
    "    url = pdict[partition]\n",
    "    columns = 'https://dsci551-project-52d43-default-rtdb.firebaseio.com/DataNode/Country_Name/Stats_Cap_Ind.json'\n",
    "    rlist =[ v for k, v in requests.get(columns).json().items()]\n",
    "    getRead = indexing(requests.get(url).json())\n",
    "    for key in sorted(getRead):\n",
    "        rlist.append(getRead[key])\n",
    "    return rlist\n",
    "    \n",
    "#     return requests.get(url).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adab086",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = readPartition('user/Stats_Cap_Ind', 'China') # returns a list of rows\n",
    "# print(a)\n",
    "df = pd.DataFrame(columns = a[0].split(';'), data=[row.split(';') for row in a[1:]])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246e2052",
   "metadata": {},
   "source": [
    "### CAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bac414",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat(path):\n",
    "    file = path.replace('.csv','')\n",
    "    pdict = getPartitionLocation(file)\n",
    "    data = dict()\n",
    "    for k,v in pdict.items():\n",
    "#         print(v)\n",
    "        getPartition =requests.get(v).json()\n",
    "        for key, val in getPartition.items():\n",
    "            i = int(key.replace('p',''))\n",
    "            data[i]=val.replace(';',',')\n",
    "            \n",
    "# Option 1: sort and return in a list\n",
    "    ldata = list()\n",
    "    for key in sorted(data):\n",
    "        ldata.append(data[key])\n",
    "    return ldata\n",
    "\n",
    "# Option2: sort and return in a dictionary\n",
    "#         data[k] = requests.get(v).json()\n",
    "#     return (OrderedDict(sorted(data.items())))\n",
    "\n",
    "\n",
    "def sprint(dct):\n",
    "    for key in sorted(dct):\n",
    "        print(dct[key])\n",
    "#         with open('testcsv.csv','w') as csvOut:\n",
    "#             csvOut.write(dct[key])\n",
    "    \n",
    "# df = pd.DataFrame.from_dict(r.json())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fe9ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"user/Stats_Cap_Ind.csv\"\n",
    "data = cat(file)\n",
    "print(data)\n",
    "# sprint(data)\n",
    "# df = pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda0d930",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in data:\n",
    "    print (d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2857b8bc",
   "metadata": {},
   "source": [
    "### mapPartition( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e7813f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapPartition(p):\n",
    "    columns = 'https://dsci551-project-52d43-default-rtdb.firebaseio.com/DataNode/Country_Name/Stats_Cap_Ind.json'\n",
    "    rlist =[ v for k, v in requests.get(columns).json().items()]\n",
    "    readMap = indexing(requests.get(p).json())\n",
    "    for key in sorted(readMap):\n",
    "        rlist.append(readMap[key])\n",
    "    return rlist \n",
    "    \n",
    "# function to get year columns\n",
    "def is_year (c):\n",
    "    return any(char.isdigit() for char in c)    \n",
    "\n",
    "def new_col(cols):\n",
    "    new_col = list()\n",
    "    for c in cols:\n",
    "        if is_year(c):\n",
    "            new_col.append(c[:4])\n",
    "        else:\n",
    "            new_col.append(c)\n",
    "    return new_col\n",
    "    \n",
    "def to_df(data):\n",
    "    df = pd.DataFrame(columns = data[0].split(';'), data=[row.split(';') for row in data[1:]])\n",
    "    columns = new_col(df.columns.values)\n",
    "    df.columns = columns\n",
    "    df_melted = df.melt(id_vars=columns[:4], var_name='Year', value_name='Value')\n",
    "    return df_melted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1dc0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"user/Stats_Cap_Ind\"\n",
    "partitions = getPartitionLocation(file)\n",
    "\n",
    "df_list = list()\n",
    "for key,dir in partitions.items():\n",
    "    map = mapPartition(dir)\n",
    "#     print(map)\n",
    "    df_list.append(to_df(map))\n",
    "\n",
    "#maybe a dictionary???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2ed415",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00b8443",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
